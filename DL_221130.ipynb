{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyO+YcVkw7QjCQlHqGdPab",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bongkyunSON/Deep_Leaning/blob/main/DL_221130.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2w12YVcOtsuY",
        "outputId": "4550ac24-d7ec-49ff-dc13-6bbcb8b57a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### tf.keras Practice!\n",
        "\n",
        "- CIFAR10 이미지 데이터셋을 분류하는 문제를 풀어봅니다!"
      ],
      "metadata": {
        "id": "nj_TGjqct0jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "# os.cpu_count()\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8auySwJvGlW",
        "outputId": "71486d84-b3ae-450a-c407-ae0f8be12863"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Nov 30 08:05:39 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1V3B5--qttEF",
        "outputId": "349583e7-d5c8-4203-8e32-351e89223bb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# import tensorflow layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPool2D"
      ],
      "metadata": {
        "id": "NhEIZka_t1bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Datasets\n",
        "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
        "\n",
        "print(X_train.shape) # 4차원 Tensor\n",
        "## 32 x 32 x 3(RGB-channel) -> 이미지당 pixel 개수.\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "# RGB (3-channel)\n",
        "# 32 x 32 - R -> pixel matrix\n",
        "# 32 x 32 - G\n",
        "# 32 x 32 - B\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "1차원은 백터\n",
        "2차원은 메트릭\n",
        "3차원 이상은 텐서\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "s5Gl_3giktBu",
        "outputId": "22075c69-ebed-4772-a2b4-32753d9afbed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 13s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n1차원은 백터\\n2차원은 메트릭\\n3차원 이상은 텐서\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocessing\n",
        "\n",
        "Input Normalization"
      ],
      "metadata": {
        "id": "SARCQ0TSk5Qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# min-max scaling\n",
        "# RGB, 3-channel color [0, 255] 24bit True color\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "X_train[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ38cpRgk9bb",
        "outputId": "8f55dfaa-3ba8-4be6-9309-d8d762a1158d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.23137255, 0.24313725, 0.24705882],\n",
              "        [0.16862745, 0.18039216, 0.17647059],\n",
              "        [0.19607843, 0.18823529, 0.16862745],\n",
              "        ...,\n",
              "        [0.61960784, 0.51764706, 0.42352941],\n",
              "        [0.59607843, 0.49019608, 0.4       ],\n",
              "        [0.58039216, 0.48627451, 0.40392157]],\n",
              "\n",
              "       [[0.0627451 , 0.07843137, 0.07843137],\n",
              "        [0.        , 0.        , 0.        ],\n",
              "        [0.07058824, 0.03137255, 0.        ],\n",
              "        ...,\n",
              "        [0.48235294, 0.34509804, 0.21568627],\n",
              "        [0.46666667, 0.3254902 , 0.19607843],\n",
              "        [0.47843137, 0.34117647, 0.22352941]],\n",
              "\n",
              "       [[0.09803922, 0.09411765, 0.08235294],\n",
              "        [0.0627451 , 0.02745098, 0.        ],\n",
              "        [0.19215686, 0.10588235, 0.03137255],\n",
              "        ...,\n",
              "        [0.4627451 , 0.32941176, 0.19607843],\n",
              "        [0.47058824, 0.32941176, 0.19607843],\n",
              "        [0.42745098, 0.28627451, 0.16470588]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.81568627, 0.66666667, 0.37647059],\n",
              "        [0.78823529, 0.6       , 0.13333333],\n",
              "        [0.77647059, 0.63137255, 0.10196078],\n",
              "        ...,\n",
              "        [0.62745098, 0.52156863, 0.2745098 ],\n",
              "        [0.21960784, 0.12156863, 0.02745098],\n",
              "        [0.20784314, 0.13333333, 0.07843137]],\n",
              "\n",
              "       [[0.70588235, 0.54509804, 0.37647059],\n",
              "        [0.67843137, 0.48235294, 0.16470588],\n",
              "        [0.72941176, 0.56470588, 0.11764706],\n",
              "        ...,\n",
              "        [0.72156863, 0.58039216, 0.36862745],\n",
              "        [0.38039216, 0.24313725, 0.13333333],\n",
              "        [0.3254902 , 0.20784314, 0.13333333]],\n",
              "\n",
              "       [[0.69411765, 0.56470588, 0.45490196],\n",
              "        [0.65882353, 0.50588235, 0.36862745],\n",
              "        [0.70196078, 0.55686275, 0.34117647],\n",
              "        ...,\n",
              "        [0.84705882, 0.72156863, 0.54901961],\n",
              "        [0.59215686, 0.4627451 , 0.32941176],\n",
              "        [0.48235294, 0.36078431, 0.28235294]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Vanilla CNN\n",
        "\n",
        "**Model Architecture**\n",
        "\n",
        "> Conv - Relu - Conv - Relu - FC - FC\n"
      ],
      "metadata": {
        "id": "ggDV4UsWlAQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequential 객체를 이용하여 layer를 쌓아올려 모델을 만듭니다.\n",
        "model = Sequential([\n",
        "    Input(shape=(32, 32, 3)),\n",
        "    Conv2D(filters=6,\n",
        "           kernel_size=3,\n",
        "           strides=1,\n",
        "           padding='same',\n",
        "           activation='relu'),\n",
        "    Conv2D(16, 5, 1, 'same', activation='relu'),\n",
        "    MaxPool2D(pool_size=2, strides=2),\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu'),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(10, activation='softmax')\n",
        "\n",
        "    \n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJHfMLGLlEkw",
        "outputId": "51722414-d062-4636-b691-c45cbc3733ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_10 (Conv2D)          (None, 32, 32, 6)         168       \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 32, 32, 16)        2416      \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1024)              4195328   \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 128)               131200    \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,330,402\n",
            "Trainable params: 4,330,402\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training setup\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "## config variables\n",
        "batch_size = 128\n",
        "lr = 1e-3\n",
        "epochs = 30\n",
        "\n",
        "# Set optimizer, loss function, metrics, callback function\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "# categorical_crossentropy : target value가 이미 one-hot vector인 경우\n",
        "# sparse_categorical_crossentropy : 그냥 정수\n",
        "\n",
        "loss_fn = 'sparse_categorical_crossentropy' # multi-class classification\n",
        "metrics = ['accuracy']\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=metrics)"
      ],
      "metadata": {
        "id": "iWMLAZo6lLG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model training\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    validation_data=(X_test, y_test), # 매 epoch마다 validation 성능 체크 가능!\n",
        "                    verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bbvcll7tlN0R",
        "outputId": "01bf692a-f59c-4148-fbc5-918cb2f709b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "391/391 - 3s - loss: 1.5259 - accuracy: 0.4481 - val_loss: 1.2324 - val_accuracy: 0.5596 - 3s/epoch - 9ms/step\n",
            "Epoch 2/30\n",
            "391/391 - 3s - loss: 1.1331 - accuracy: 0.5986 - val_loss: 1.0891 - val_accuracy: 0.6176 - 3s/epoch - 7ms/step\n",
            "Epoch 3/30\n",
            "391/391 - 3s - loss: 0.9549 - accuracy: 0.6612 - val_loss: 1.0203 - val_accuracy: 0.6438 - 3s/epoch - 7ms/step\n",
            "Epoch 4/30\n",
            "391/391 - 3s - loss: 0.8126 - accuracy: 0.7143 - val_loss: 0.9776 - val_accuracy: 0.6616 - 3s/epoch - 7ms/step\n",
            "Epoch 5/30\n",
            "391/391 - 3s - loss: 0.6727 - accuracy: 0.7639 - val_loss: 0.9606 - val_accuracy: 0.6723 - 3s/epoch - 7ms/step\n",
            "Epoch 6/30\n",
            "391/391 - 3s - loss: 0.5310 - accuracy: 0.8142 - val_loss: 0.9947 - val_accuracy: 0.6742 - 3s/epoch - 7ms/step\n",
            "Epoch 7/30\n",
            "391/391 - 3s - loss: 0.3867 - accuracy: 0.8675 - val_loss: 1.0612 - val_accuracy: 0.6756 - 3s/epoch - 7ms/step\n",
            "Epoch 8/30\n",
            "391/391 - 3s - loss: 0.2638 - accuracy: 0.9102 - val_loss: 1.2059 - val_accuracy: 0.6687 - 3s/epoch - 7ms/step\n",
            "Epoch 9/30\n",
            "391/391 - 3s - loss: 0.1602 - accuracy: 0.9472 - val_loss: 1.3318 - val_accuracy: 0.6751 - 3s/epoch - 7ms/step\n",
            "Epoch 10/30\n",
            "391/391 - 3s - loss: 0.1045 - accuracy: 0.9667 - val_loss: 1.6126 - val_accuracy: 0.6751 - 3s/epoch - 7ms/step\n",
            "Epoch 11/30\n",
            "391/391 - 3s - loss: 0.0755 - accuracy: 0.9761 - val_loss: 1.8437 - val_accuracy: 0.6691 - 3s/epoch - 7ms/step\n",
            "Epoch 12/30\n",
            "391/391 - 3s - loss: 0.0702 - accuracy: 0.9772 - val_loss: 1.8327 - val_accuracy: 0.6670 - 3s/epoch - 7ms/step\n",
            "Epoch 13/30\n",
            "391/391 - 3s - loss: 0.0658 - accuracy: 0.9781 - val_loss: 2.0235 - val_accuracy: 0.6683 - 3s/epoch - 7ms/step\n",
            "Epoch 14/30\n",
            "391/391 - 3s - loss: 0.0518 - accuracy: 0.9826 - val_loss: 2.0404 - val_accuracy: 0.6667 - 3s/epoch - 7ms/step\n",
            "Epoch 15/30\n",
            "391/391 - 3s - loss: 0.0547 - accuracy: 0.9817 - val_loss: 2.0625 - val_accuracy: 0.6650 - 3s/epoch - 7ms/step\n",
            "Epoch 16/30\n",
            "391/391 - 3s - loss: 0.0542 - accuracy: 0.9814 - val_loss: 2.1499 - val_accuracy: 0.6650 - 3s/epoch - 7ms/step\n",
            "Epoch 17/30\n",
            "391/391 - 3s - loss: 0.0413 - accuracy: 0.9858 - val_loss: 2.4465 - val_accuracy: 0.6609 - 3s/epoch - 7ms/step\n",
            "Epoch 18/30\n",
            "391/391 - 3s - loss: 0.0415 - accuracy: 0.9864 - val_loss: 2.3563 - val_accuracy: 0.6691 - 3s/epoch - 7ms/step\n",
            "Epoch 19/30\n",
            "391/391 - 3s - loss: 0.0477 - accuracy: 0.9831 - val_loss: 2.2753 - val_accuracy: 0.6596 - 3s/epoch - 9ms/step\n",
            "Epoch 20/30\n",
            "391/391 - 4s - loss: 0.0331 - accuracy: 0.9889 - val_loss: 2.6098 - val_accuracy: 0.6667 - 4s/epoch - 9ms/step\n",
            "Epoch 21/30\n",
            "391/391 - 3s - loss: 0.0354 - accuracy: 0.9880 - val_loss: 2.4474 - val_accuracy: 0.6703 - 3s/epoch - 7ms/step\n",
            "Epoch 22/30\n",
            "391/391 - 3s - loss: 0.0317 - accuracy: 0.9892 - val_loss: 2.6730 - val_accuracy: 0.6592 - 3s/epoch - 7ms/step\n",
            "Epoch 23/30\n",
            "391/391 - 3s - loss: 0.0386 - accuracy: 0.9873 - val_loss: 2.7457 - val_accuracy: 0.6557 - 3s/epoch - 7ms/step\n",
            "Epoch 24/30\n",
            "391/391 - 3s - loss: 0.0387 - accuracy: 0.9875 - val_loss: 2.5185 - val_accuracy: 0.6630 - 3s/epoch - 7ms/step\n",
            "Epoch 25/30\n",
            "391/391 - 3s - loss: 0.0388 - accuracy: 0.9872 - val_loss: 2.6612 - val_accuracy: 0.6682 - 3s/epoch - 7ms/step\n",
            "Epoch 26/30\n",
            "391/391 - 3s - loss: 0.0237 - accuracy: 0.9921 - val_loss: 2.8951 - val_accuracy: 0.6570 - 3s/epoch - 7ms/step\n",
            "Epoch 27/30\n",
            "391/391 - 3s - loss: 0.0363 - accuracy: 0.9879 - val_loss: 2.7731 - val_accuracy: 0.6645 - 3s/epoch - 7ms/step\n",
            "Epoch 28/30\n",
            "391/391 - 3s - loss: 0.0257 - accuracy: 0.9918 - val_loss: 3.0121 - val_accuracy: 0.6573 - 3s/epoch - 7ms/step\n",
            "Epoch 29/30\n",
            "391/391 - 3s - loss: 0.0327 - accuracy: 0.9899 - val_loss: 2.9325 - val_accuracy: 0.6509 - 3s/epoch - 7ms/step\n",
            "Epoch 30/30\n",
            "391/391 - 3s - loss: 0.0267 - accuracy: 0.9914 - val_loss: 2.9238 - val_accuracy: 0.6600 - 3s/epoch - 7ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print(\"Loss : %.4f, Accuracy : %.4f\" % (loss, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VbzYmm8zlP26",
        "outputId": "f74fe10c-a63b-44ed-f539-a7d048c7897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 4ms/step - loss: 2.9238 - accuracy: 0.6600\n",
            "Loss : 2.9238, Accuracy : 0.6600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## loss visualize\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.subplot(1, 2,1)\n",
        "plt.plot(history.history['loss'],'b-', label = \"training\")\n",
        "plt.plot(history.history['val_loss'], 'r:', label = \"validation\")\n",
        "plt.title(\"model - loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"model - accuracy\")\n",
        "\n",
        "plt.plot(history.history['accuracy'], 'b-', label = \"training\")\n",
        "plt.plot(history.history['val_accuracy'], 'r:', label = \"validation\")\n",
        "\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "t2jLCVZ-lRFc",
        "outputId": "0578d52a-a164-46cc-b0a7-c73833197cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Training\n",
        "\n",
        "1. model architecture\n",
        "\n",
        "- Hidden Layer (뒤로 갈수록 hidden node수가 작아짐)\n",
        "\n",
        "- Activation function : 'sigmoid' / 'relu'\n",
        "\n",
        "\n",
        "\n",
        "2. loss optimization\n",
        "\n",
        "\n",
        "- optimizer : 'sgd', 'momentum', 'adam'\n",
        "\n",
        "- batch_size : 1 -> 8-> 32 -> 64 -> 128 -> 256 -> 512 -> 2048 -> ...\n",
        "\n",
        "- epochs : 10 -> 30 -> 100 -> 10000 (overfitting) "
      ],
      "metadata": {
        "id": "rQEcNEknt8lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(3072+1)*1024"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LysQAh2E06UB",
        "outputId": "2c4b50be-65fe-4f36-e42b-a518b34bf256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3146752"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(32, 32, 3)),\n",
        "    Flatten(),   # 32x32x3 ----> 3072 (input layer의 node 수)\n",
        "    Dense(units=1024, activation='relu'),\n",
        "    Dense(units=256, activation='relu'),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=10, activation='softmax')  # output layer\n",
        "])\n",
        "\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrvWgGy7t620",
        "outputId": "857d5c6a-91bd-4421-9d3e-181863a34ee2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_7 (Flatten)         (None, 3072)              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 1024)              3146752   \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 256)               262400    \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,443,338\n",
            "Trainable params: 3,443,338\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train # 0 ~ 9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XPPB7XK52b2_",
        "outputId": "9bc68486-7811-4fce-a9de-075658090d2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6],\n",
              "       [9],\n",
              "       [9],\n",
              "       ...,\n",
              "       [9],\n",
              "       [1],\n",
              "       [1]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# compile\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "\n",
        "lr = 1e-4\n",
        "epochs = 200\n",
        "batch_size = 128\n",
        "\n",
        "# 모든데이터가 학습에 다 사용되면 1 epoch\n",
        "# epochs : 전체 데이터를 몇번 반복 학습을 수행한건지.\n",
        "# iterations : 실제로 weghit update를 한 횟수.\n",
        "\n",
        "\n",
        "loss_fn = 'sparse_categorical_crossentropy'  #target vector가 정수인 경우.\n",
        "# optimizer = SGD(learning_rate=lr) #learning rate 조절을 위해서 보통 함수로 구현.\n",
        "# optimizer = SGD(learning_rate=lr, momentum=0.9)\n",
        "optimizer = Adam(learning_rate=lr)\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss=loss_fn,\n",
        "              metrics=['accuracy']\n",
        "              )"
      ],
      "metadata": {
        "id": "V4kJC2uRuCQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit\n",
        "model.fit(x=X_train,\n",
        "          y=y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6bKWZmjuCeY",
        "outputId": "a9a1176b-3c8b-462b-a648-ee0dd63e7305"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "391/391 - 2s - loss: 11.5867 - accuracy: 0.2440 - val_loss: 4.8217 - val_accuracy: 0.2771 - 2s/epoch - 5ms/step\n",
            "Epoch 2/200\n",
            "391/391 - 1s - loss: 4.4090 - accuracy: 0.2928 - val_loss: 3.7697 - val_accuracy: 0.3124 - 1s/epoch - 3ms/step\n",
            "Epoch 3/200\n",
            "391/391 - 1s - loss: 3.5582 - accuracy: 0.3185 - val_loss: 4.8723 - val_accuracy: 0.2506 - 1s/epoch - 3ms/step\n",
            "Epoch 4/200\n",
            "391/391 - 1s - loss: 3.0897 - accuracy: 0.3375 - val_loss: 2.9197 - val_accuracy: 0.3226 - 1s/epoch - 3ms/step\n",
            "Epoch 5/200\n",
            "391/391 - 1s - loss: 2.7835 - accuracy: 0.3523 - val_loss: 2.9289 - val_accuracy: 0.3179 - 1s/epoch - 3ms/step\n",
            "Epoch 6/200\n",
            "391/391 - 1s - loss: 2.5064 - accuracy: 0.3722 - val_loss: 2.4738 - val_accuracy: 0.3770 - 1s/epoch - 3ms/step\n",
            "Epoch 7/200\n",
            "391/391 - 1s - loss: 2.3281 - accuracy: 0.3862 - val_loss: 2.6446 - val_accuracy: 0.3600 - 1s/epoch - 3ms/step\n",
            "Epoch 8/200\n",
            "391/391 - 1s - loss: 2.1773 - accuracy: 0.4009 - val_loss: 2.6156 - val_accuracy: 0.3631 - 1s/epoch - 3ms/step\n",
            "Epoch 9/200\n",
            "391/391 - 1s - loss: 2.1579 - accuracy: 0.4058 - val_loss: 2.3472 - val_accuracy: 0.3689 - 1s/epoch - 3ms/step\n",
            "Epoch 10/200\n",
            "391/391 - 1s - loss: 1.9869 - accuracy: 0.4246 - val_loss: 2.2890 - val_accuracy: 0.3834 - 1s/epoch - 3ms/step\n",
            "Epoch 11/200\n",
            "391/391 - 1s - loss: 1.9312 - accuracy: 0.4303 - val_loss: 2.0829 - val_accuracy: 0.3877 - 1s/epoch - 3ms/step\n",
            "Epoch 12/200\n",
            "391/391 - 1s - loss: 1.8512 - accuracy: 0.4429 - val_loss: 1.9147 - val_accuracy: 0.4163 - 1s/epoch - 3ms/step\n",
            "Epoch 13/200\n",
            "391/391 - 1s - loss: 1.7262 - accuracy: 0.4586 - val_loss: 2.1542 - val_accuracy: 0.4065 - 1s/epoch - 3ms/step\n",
            "Epoch 14/200\n",
            "391/391 - 1s - loss: 1.7161 - accuracy: 0.4615 - val_loss: 2.0613 - val_accuracy: 0.3793 - 1s/epoch - 3ms/step\n",
            "Epoch 15/200\n",
            "391/391 - 1s - loss: 1.6328 - accuracy: 0.4720 - val_loss: 1.9045 - val_accuracy: 0.4194 - 1s/epoch - 3ms/step\n",
            "Epoch 16/200\n",
            "391/391 - 1s - loss: 1.5877 - accuracy: 0.4793 - val_loss: 1.9735 - val_accuracy: 0.3934 - 1s/epoch - 3ms/step\n",
            "Epoch 17/200\n",
            "391/391 - 1s - loss: 1.5827 - accuracy: 0.4832 - val_loss: 1.9481 - val_accuracy: 0.4079 - 1s/epoch - 3ms/step\n",
            "Epoch 18/200\n",
            "391/391 - 1s - loss: 1.5350 - accuracy: 0.4925 - val_loss: 1.8765 - val_accuracy: 0.4303 - 1s/epoch - 3ms/step\n",
            "Epoch 19/200\n",
            "391/391 - 1s - loss: 1.4774 - accuracy: 0.5028 - val_loss: 1.7866 - val_accuracy: 0.4397 - 1s/epoch - 3ms/step\n",
            "Epoch 20/200\n",
            "391/391 - 1s - loss: 1.4785 - accuracy: 0.5061 - val_loss: 1.6991 - val_accuracy: 0.4468 - 1s/epoch - 4ms/step\n",
            "Epoch 21/200\n",
            "391/391 - 1s - loss: 1.4110 - accuracy: 0.5181 - val_loss: 1.6388 - val_accuracy: 0.4632 - 1s/epoch - 4ms/step\n",
            "Epoch 22/200\n",
            "391/391 - 1s - loss: 1.4126 - accuracy: 0.5189 - val_loss: 1.6581 - val_accuracy: 0.4564 - 1s/epoch - 4ms/step\n",
            "Epoch 23/200\n",
            "391/391 - 1s - loss: 1.3665 - accuracy: 0.5270 - val_loss: 1.7865 - val_accuracy: 0.4119 - 1s/epoch - 3ms/step\n",
            "Epoch 24/200\n",
            "391/391 - 1s - loss: 1.3341 - accuracy: 0.5363 - val_loss: 1.7612 - val_accuracy: 0.4337 - 1s/epoch - 3ms/step\n",
            "Epoch 25/200\n",
            "391/391 - 1s - loss: 1.3398 - accuracy: 0.5364 - val_loss: 1.5557 - val_accuracy: 0.4854 - 1s/epoch - 4ms/step\n",
            "Epoch 26/200\n",
            "391/391 - 1s - loss: 1.3229 - accuracy: 0.5398 - val_loss: 1.8108 - val_accuracy: 0.4379 - 1s/epoch - 3ms/step\n",
            "Epoch 27/200\n",
            "391/391 - 1s - loss: 1.2891 - accuracy: 0.5501 - val_loss: 1.6513 - val_accuracy: 0.4544 - 1s/epoch - 3ms/step\n",
            "Epoch 28/200\n",
            "391/391 - 1s - loss: 1.2469 - accuracy: 0.5607 - val_loss: 1.6227 - val_accuracy: 0.4684 - 1s/epoch - 4ms/step\n",
            "Epoch 29/200\n",
            "391/391 - 1s - loss: 1.2559 - accuracy: 0.5622 - val_loss: 1.5643 - val_accuracy: 0.4756 - 1s/epoch - 4ms/step\n",
            "Epoch 30/200\n",
            "391/391 - 1s - loss: 1.2450 - accuracy: 0.5627 - val_loss: 1.6380 - val_accuracy: 0.4738 - 1s/epoch - 4ms/step\n",
            "Epoch 31/200\n",
            "391/391 - 1s - loss: 1.2112 - accuracy: 0.5758 - val_loss: 1.7309 - val_accuracy: 0.4349 - 1s/epoch - 3ms/step\n",
            "Epoch 32/200\n",
            "391/391 - 1s - loss: 1.2000 - accuracy: 0.5759 - val_loss: 1.7791 - val_accuracy: 0.4489 - 1s/epoch - 3ms/step\n",
            "Epoch 33/200\n",
            "391/391 - 1s - loss: 1.1889 - accuracy: 0.5795 - val_loss: 1.6250 - val_accuracy: 0.4691 - 1s/epoch - 3ms/step\n",
            "Epoch 34/200\n",
            "391/391 - 1s - loss: 1.1630 - accuracy: 0.5898 - val_loss: 1.6109 - val_accuracy: 0.4772 - 1s/epoch - 3ms/step\n",
            "Epoch 35/200\n",
            "391/391 - 1s - loss: 1.1557 - accuracy: 0.5922 - val_loss: 1.5987 - val_accuracy: 0.4774 - 1s/epoch - 3ms/step\n",
            "Epoch 36/200\n",
            "391/391 - 1s - loss: 1.1437 - accuracy: 0.5964 - val_loss: 1.6095 - val_accuracy: 0.4817 - 1s/epoch - 3ms/step\n",
            "Epoch 37/200\n",
            "391/391 - 1s - loss: 1.1296 - accuracy: 0.5983 - val_loss: 1.6330 - val_accuracy: 0.4825 - 1s/epoch - 3ms/step\n",
            "Epoch 38/200\n",
            "391/391 - 1s - loss: 1.1166 - accuracy: 0.6040 - val_loss: 1.6087 - val_accuracy: 0.4801 - 1s/epoch - 3ms/step\n",
            "Epoch 39/200\n",
            "391/391 - 1s - loss: 1.1087 - accuracy: 0.6063 - val_loss: 1.6813 - val_accuracy: 0.4688 - 1s/epoch - 3ms/step\n",
            "Epoch 40/200\n",
            "391/391 - 1s - loss: 1.0906 - accuracy: 0.6141 - val_loss: 1.5872 - val_accuracy: 0.4959 - 1s/epoch - 3ms/step\n",
            "Epoch 41/200\n",
            "391/391 - 1s - loss: 1.0742 - accuracy: 0.6198 - val_loss: 1.5760 - val_accuracy: 0.4948 - 1s/epoch - 3ms/step\n",
            "Epoch 42/200\n",
            "391/391 - 1s - loss: 1.0640 - accuracy: 0.6226 - val_loss: 1.6114 - val_accuracy: 0.4937 - 1s/epoch - 3ms/step\n",
            "Epoch 43/200\n",
            "391/391 - 1s - loss: 1.0490 - accuracy: 0.6285 - val_loss: 1.5996 - val_accuracy: 0.4936 - 1s/epoch - 3ms/step\n",
            "Epoch 44/200\n",
            "391/391 - 1s - loss: 1.0244 - accuracy: 0.6373 - val_loss: 1.6484 - val_accuracy: 0.4871 - 1s/epoch - 3ms/step\n",
            "Epoch 45/200\n",
            "391/391 - 1s - loss: 1.0159 - accuracy: 0.6417 - val_loss: 1.6721 - val_accuracy: 0.4809 - 1s/epoch - 3ms/step\n",
            "Epoch 46/200\n",
            "391/391 - 1s - loss: 0.9981 - accuracy: 0.6447 - val_loss: 1.7320 - val_accuracy: 0.4752 - 1s/epoch - 3ms/step\n",
            "Epoch 47/200\n",
            "391/391 - 1s - loss: 1.0006 - accuracy: 0.6441 - val_loss: 1.6476 - val_accuracy: 0.4985 - 1s/epoch - 3ms/step\n",
            "Epoch 48/200\n",
            "391/391 - 1s - loss: 0.9862 - accuracy: 0.6517 - val_loss: 1.5971 - val_accuracy: 0.5062 - 1s/epoch - 3ms/step\n",
            "Epoch 49/200\n",
            "391/391 - 1s - loss: 0.9787 - accuracy: 0.6527 - val_loss: 1.6608 - val_accuracy: 0.4987 - 1s/epoch - 3ms/step\n",
            "Epoch 50/200\n",
            "391/391 - 1s - loss: 0.9601 - accuracy: 0.6589 - val_loss: 1.6502 - val_accuracy: 0.5005 - 1s/epoch - 3ms/step\n",
            "Epoch 51/200\n",
            "391/391 - 1s - loss: 0.9517 - accuracy: 0.6615 - val_loss: 1.6670 - val_accuracy: 0.5001 - 1s/epoch - 3ms/step\n",
            "Epoch 52/200\n",
            "391/391 - 1s - loss: 0.9339 - accuracy: 0.6702 - val_loss: 1.6648 - val_accuracy: 0.4949 - 1s/epoch - 3ms/step\n",
            "Epoch 53/200\n",
            "391/391 - 1s - loss: 0.9170 - accuracy: 0.6754 - val_loss: 1.6772 - val_accuracy: 0.4960 - 1s/epoch - 3ms/step\n",
            "Epoch 54/200\n",
            "391/391 - 1s - loss: 0.9104 - accuracy: 0.6767 - val_loss: 1.7089 - val_accuracy: 0.4998 - 1s/epoch - 3ms/step\n",
            "Epoch 55/200\n",
            "391/391 - 1s - loss: 0.8972 - accuracy: 0.6813 - val_loss: 1.7561 - val_accuracy: 0.4942 - 1s/epoch - 3ms/step\n",
            "Epoch 56/200\n",
            "391/391 - 1s - loss: 0.8873 - accuracy: 0.6862 - val_loss: 1.6882 - val_accuracy: 0.5105 - 1s/epoch - 3ms/step\n",
            "Epoch 57/200\n",
            "391/391 - 1s - loss: 0.8706 - accuracy: 0.6899 - val_loss: 1.7185 - val_accuracy: 0.5038 - 1s/epoch - 3ms/step\n",
            "Epoch 58/200\n",
            "391/391 - 1s - loss: 0.8579 - accuracy: 0.6958 - val_loss: 1.7325 - val_accuracy: 0.5121 - 1s/epoch - 3ms/step\n",
            "Epoch 59/200\n",
            "391/391 - 1s - loss: 0.8525 - accuracy: 0.6994 - val_loss: 1.7290 - val_accuracy: 0.5079 - 1s/epoch - 3ms/step\n",
            "Epoch 60/200\n",
            "391/391 - 1s - loss: 0.8328 - accuracy: 0.7059 - val_loss: 1.7121 - val_accuracy: 0.5102 - 1s/epoch - 3ms/step\n",
            "Epoch 61/200\n",
            "391/391 - 1s - loss: 0.8192 - accuracy: 0.7092 - val_loss: 1.7753 - val_accuracy: 0.5057 - 1s/epoch - 3ms/step\n",
            "Epoch 62/200\n",
            "391/391 - 1s - loss: 0.8262 - accuracy: 0.7094 - val_loss: 1.7654 - val_accuracy: 0.4982 - 1s/epoch - 3ms/step\n",
            "Epoch 63/200\n",
            "391/391 - 1s - loss: 0.8038 - accuracy: 0.7163 - val_loss: 1.8346 - val_accuracy: 0.4938 - 1s/epoch - 3ms/step\n",
            "Epoch 64/200\n",
            "391/391 - 1s - loss: 0.7947 - accuracy: 0.7176 - val_loss: 1.7949 - val_accuracy: 0.4977 - 1s/epoch - 3ms/step\n",
            "Epoch 65/200\n",
            "391/391 - 1s - loss: 0.7879 - accuracy: 0.7209 - val_loss: 1.8900 - val_accuracy: 0.4994 - 1s/epoch - 3ms/step\n",
            "Epoch 66/200\n",
            "391/391 - 1s - loss: 0.7650 - accuracy: 0.7290 - val_loss: 1.8603 - val_accuracy: 0.5008 - 1s/epoch - 3ms/step\n",
            "Epoch 67/200\n",
            "391/391 - 1s - loss: 0.7603 - accuracy: 0.7311 - val_loss: 1.8693 - val_accuracy: 0.4875 - 1s/epoch - 3ms/step\n",
            "Epoch 68/200\n",
            "391/391 - 1s - loss: 0.7611 - accuracy: 0.7276 - val_loss: 1.9627 - val_accuracy: 0.4972 - 1s/epoch - 3ms/step\n",
            "Epoch 69/200\n",
            "391/391 - 1s - loss: 0.7414 - accuracy: 0.7380 - val_loss: 1.8387 - val_accuracy: 0.5153 - 1s/epoch - 3ms/step\n",
            "Epoch 70/200\n",
            "391/391 - 1s - loss: 0.7291 - accuracy: 0.7417 - val_loss: 1.9555 - val_accuracy: 0.5011 - 1s/epoch - 3ms/step\n",
            "Epoch 71/200\n",
            "391/391 - 1s - loss: 0.7301 - accuracy: 0.7422 - val_loss: 1.9063 - val_accuracy: 0.5037 - 1s/epoch - 3ms/step\n",
            "Epoch 72/200\n",
            "391/391 - 1s - loss: 0.7164 - accuracy: 0.7455 - val_loss: 1.9962 - val_accuracy: 0.4847 - 1s/epoch - 3ms/step\n",
            "Epoch 73/200\n",
            "391/391 - 1s - loss: 0.7082 - accuracy: 0.7494 - val_loss: 1.9365 - val_accuracy: 0.5059 - 1s/epoch - 3ms/step\n",
            "Epoch 74/200\n",
            "391/391 - 1s - loss: 0.7026 - accuracy: 0.7525 - val_loss: 2.0301 - val_accuracy: 0.4943 - 1s/epoch - 3ms/step\n",
            "Epoch 75/200\n",
            "391/391 - 1s - loss: 0.6959 - accuracy: 0.7533 - val_loss: 2.0273 - val_accuracy: 0.4936 - 1s/epoch - 3ms/step\n",
            "Epoch 76/200\n",
            "391/391 - 1s - loss: 0.6713 - accuracy: 0.7641 - val_loss: 2.0044 - val_accuracy: 0.5033 - 1s/epoch - 3ms/step\n",
            "Epoch 77/200\n",
            "391/391 - 1s - loss: 0.6669 - accuracy: 0.7622 - val_loss: 2.0252 - val_accuracy: 0.4946 - 1s/epoch - 3ms/step\n",
            "Epoch 78/200\n",
            "391/391 - 1s - loss: 0.6615 - accuracy: 0.7665 - val_loss: 2.0957 - val_accuracy: 0.4906 - 1s/epoch - 3ms/step\n",
            "Epoch 79/200\n",
            "391/391 - 1s - loss: 0.6644 - accuracy: 0.7663 - val_loss: 2.0671 - val_accuracy: 0.4982 - 1s/epoch - 3ms/step\n",
            "Epoch 80/200\n",
            "391/391 - 1s - loss: 0.6412 - accuracy: 0.7729 - val_loss: 2.0816 - val_accuracy: 0.4942 - 1s/epoch - 3ms/step\n",
            "Epoch 81/200\n",
            "391/391 - 1s - loss: 0.6326 - accuracy: 0.7761 - val_loss: 2.1035 - val_accuracy: 0.5025 - 1s/epoch - 3ms/step\n",
            "Epoch 82/200\n",
            "391/391 - 1s - loss: 0.6100 - accuracy: 0.7846 - val_loss: 2.1626 - val_accuracy: 0.4932 - 1s/epoch - 3ms/step\n",
            "Epoch 83/200\n",
            "391/391 - 1s - loss: 0.6243 - accuracy: 0.7796 - val_loss: 2.1425 - val_accuracy: 0.5033 - 1s/epoch - 3ms/step\n",
            "Epoch 84/200\n",
            "391/391 - 1s - loss: 0.6122 - accuracy: 0.7830 - val_loss: 2.2515 - val_accuracy: 0.4838 - 1s/epoch - 3ms/step\n",
            "Epoch 85/200\n",
            "391/391 - 1s - loss: 0.5969 - accuracy: 0.7879 - val_loss: 2.2118 - val_accuracy: 0.4954 - 1s/epoch - 3ms/step\n",
            "Epoch 86/200\n",
            "391/391 - 1s - loss: 0.6033 - accuracy: 0.7856 - val_loss: 2.1395 - val_accuracy: 0.5095 - 1s/epoch - 3ms/step\n",
            "Epoch 87/200\n",
            "391/391 - 1s - loss: 0.5824 - accuracy: 0.7959 - val_loss: 2.3284 - val_accuracy: 0.4855 - 1s/epoch - 3ms/step\n",
            "Epoch 88/200\n",
            "391/391 - 1s - loss: 0.5782 - accuracy: 0.7954 - val_loss: 2.1758 - val_accuracy: 0.5075 - 1s/epoch - 3ms/step\n",
            "Epoch 89/200\n",
            "391/391 - 1s - loss: 0.5819 - accuracy: 0.7930 - val_loss: 2.2210 - val_accuracy: 0.5093 - 1s/epoch - 3ms/step\n",
            "Epoch 90/200\n",
            "391/391 - 1s - loss: 0.5678 - accuracy: 0.7969 - val_loss: 2.2091 - val_accuracy: 0.5024 - 1s/epoch - 3ms/step\n",
            "Epoch 91/200\n",
            "391/391 - 1s - loss: 0.5467 - accuracy: 0.8052 - val_loss: 2.2842 - val_accuracy: 0.5034 - 1s/epoch - 3ms/step\n",
            "Epoch 92/200\n",
            "391/391 - 1s - loss: 0.5461 - accuracy: 0.8060 - val_loss: 2.2869 - val_accuracy: 0.5017 - 1s/epoch - 3ms/step\n",
            "Epoch 93/200\n",
            "391/391 - 1s - loss: 0.5657 - accuracy: 0.7983 - val_loss: 2.3092 - val_accuracy: 0.5061 - 1s/epoch - 3ms/step\n",
            "Epoch 94/200\n",
            "391/391 - 1s - loss: 0.5493 - accuracy: 0.8060 - val_loss: 2.3239 - val_accuracy: 0.4999 - 1s/epoch - 3ms/step\n",
            "Epoch 95/200\n",
            "391/391 - 1s - loss: 0.5243 - accuracy: 0.8155 - val_loss: 2.3644 - val_accuracy: 0.5050 - 1s/epoch - 3ms/step\n",
            "Epoch 96/200\n",
            "391/391 - 1s - loss: 0.5281 - accuracy: 0.8137 - val_loss: 2.2911 - val_accuracy: 0.5049 - 1s/epoch - 3ms/step\n",
            "Epoch 97/200\n",
            "391/391 - 1s - loss: 0.5265 - accuracy: 0.8147 - val_loss: 2.3983 - val_accuracy: 0.5027 - 1s/epoch - 3ms/step\n",
            "Epoch 98/200\n",
            "391/391 - 1s - loss: 0.5081 - accuracy: 0.8199 - val_loss: 2.3634 - val_accuracy: 0.5026 - 1s/epoch - 3ms/step\n",
            "Epoch 99/200\n",
            "391/391 - 1s - loss: 0.4971 - accuracy: 0.8257 - val_loss: 2.3803 - val_accuracy: 0.5071 - 1s/epoch - 3ms/step\n",
            "Epoch 100/200\n",
            "391/391 - 1s - loss: 0.5000 - accuracy: 0.8216 - val_loss: 2.3939 - val_accuracy: 0.5035 - 1s/epoch - 3ms/step\n",
            "Epoch 101/200\n",
            "391/391 - 1s - loss: 0.5030 - accuracy: 0.8213 - val_loss: 2.3953 - val_accuracy: 0.5032 - 1s/epoch - 3ms/step\n",
            "Epoch 102/200\n",
            "391/391 - 1s - loss: 0.5086 - accuracy: 0.8173 - val_loss: 2.4959 - val_accuracy: 0.5007 - 1s/epoch - 3ms/step\n",
            "Epoch 103/200\n",
            "391/391 - 1s - loss: 0.4664 - accuracy: 0.8352 - val_loss: 2.5899 - val_accuracy: 0.4945 - 1s/epoch - 3ms/step\n",
            "Epoch 104/200\n",
            "391/391 - 1s - loss: 0.4947 - accuracy: 0.8251 - val_loss: 2.5524 - val_accuracy: 0.4836 - 1s/epoch - 3ms/step\n",
            "Epoch 105/200\n",
            "391/391 - 1s - loss: 0.4683 - accuracy: 0.8342 - val_loss: 2.5460 - val_accuracy: 0.5004 - 1s/epoch - 3ms/step\n",
            "Epoch 106/200\n",
            "391/391 - 1s - loss: 0.4612 - accuracy: 0.8365 - val_loss: 2.4763 - val_accuracy: 0.5064 - 1s/epoch - 3ms/step\n",
            "Epoch 107/200\n",
            "391/391 - 1s - loss: 0.4559 - accuracy: 0.8387 - val_loss: 2.4883 - val_accuracy: 0.5006 - 1s/epoch - 3ms/step\n",
            "Epoch 108/200\n",
            "391/391 - 1s - loss: 0.4531 - accuracy: 0.8397 - val_loss: 2.5472 - val_accuracy: 0.5041 - 1s/epoch - 3ms/step\n",
            "Epoch 109/200\n",
            "391/391 - 1s - loss: 0.4594 - accuracy: 0.8372 - val_loss: 2.6267 - val_accuracy: 0.5001 - 1s/epoch - 3ms/step\n",
            "Epoch 110/200\n",
            "391/391 - 1s - loss: 0.4428 - accuracy: 0.8438 - val_loss: 2.5776 - val_accuracy: 0.5001 - 1s/epoch - 3ms/step\n",
            "Epoch 111/200\n",
            "391/391 - 1s - loss: 0.4401 - accuracy: 0.8432 - val_loss: 2.6691 - val_accuracy: 0.5025 - 1s/epoch - 3ms/step\n",
            "Epoch 112/200\n",
            "391/391 - 1s - loss: 0.4263 - accuracy: 0.8476 - val_loss: 2.7727 - val_accuracy: 0.4851 - 1s/epoch - 3ms/step\n",
            "Epoch 113/200\n",
            "391/391 - 1s - loss: 0.4307 - accuracy: 0.8481 - val_loss: 2.6723 - val_accuracy: 0.5024 - 1s/epoch - 3ms/step\n",
            "Epoch 114/200\n",
            "391/391 - 1s - loss: 0.4227 - accuracy: 0.8502 - val_loss: 2.7291 - val_accuracy: 0.4990 - 1s/epoch - 3ms/step\n",
            "Epoch 115/200\n",
            "391/391 - 1s - loss: 0.4029 - accuracy: 0.8568 - val_loss: 2.7832 - val_accuracy: 0.5032 - 1s/epoch - 3ms/step\n",
            "Epoch 116/200\n",
            "391/391 - 1s - loss: 0.4047 - accuracy: 0.8562 - val_loss: 2.8563 - val_accuracy: 0.4866 - 1s/epoch - 3ms/step\n",
            "Epoch 117/200\n",
            "391/391 - 1s - loss: 0.4189 - accuracy: 0.8522 - val_loss: 2.8463 - val_accuracy: 0.5034 - 1s/epoch - 3ms/step\n",
            "Epoch 118/200\n",
            "391/391 - 1s - loss: 0.4097 - accuracy: 0.8552 - val_loss: 2.7249 - val_accuracy: 0.5038 - 1s/epoch - 3ms/step\n",
            "Epoch 119/200\n",
            "391/391 - 1s - loss: 0.3964 - accuracy: 0.8591 - val_loss: 2.8031 - val_accuracy: 0.5064 - 1s/epoch - 3ms/step\n",
            "Epoch 120/200\n",
            "391/391 - 1s - loss: 0.3875 - accuracy: 0.8638 - val_loss: 2.8353 - val_accuracy: 0.5031 - 1s/epoch - 3ms/step\n",
            "Epoch 121/200\n",
            "391/391 - 1s - loss: 0.3973 - accuracy: 0.8599 - val_loss: 2.9786 - val_accuracy: 0.4845 - 1s/epoch - 3ms/step\n",
            "Epoch 122/200\n",
            "391/391 - 1s - loss: 0.4006 - accuracy: 0.8575 - val_loss: 2.8079 - val_accuracy: 0.4968 - 1s/epoch - 3ms/step\n",
            "Epoch 123/200\n",
            "391/391 - 1s - loss: 0.3910 - accuracy: 0.8607 - val_loss: 2.9205 - val_accuracy: 0.5007 - 1s/epoch - 3ms/step\n",
            "Epoch 124/200\n",
            "391/391 - 1s - loss: 0.3746 - accuracy: 0.8666 - val_loss: 2.9457 - val_accuracy: 0.5056 - 1s/epoch - 3ms/step\n",
            "Epoch 125/200\n",
            "391/391 - 1s - loss: 0.3715 - accuracy: 0.8690 - val_loss: 2.8558 - val_accuracy: 0.5054 - 1s/epoch - 3ms/step\n",
            "Epoch 126/200\n",
            "391/391 - 1s - loss: 0.3515 - accuracy: 0.8754 - val_loss: 2.9404 - val_accuracy: 0.5028 - 1s/epoch - 3ms/step\n",
            "Epoch 127/200\n",
            "391/391 - 1s - loss: 0.3594 - accuracy: 0.8720 - val_loss: 3.0495 - val_accuracy: 0.4960 - 1s/epoch - 3ms/step\n",
            "Epoch 128/200\n",
            "391/391 - 1s - loss: 0.3756 - accuracy: 0.8672 - val_loss: 3.1510 - val_accuracy: 0.4966 - 1s/epoch - 3ms/step\n",
            "Epoch 129/200\n",
            "391/391 - 1s - loss: 0.3577 - accuracy: 0.8733 - val_loss: 3.0356 - val_accuracy: 0.5009 - 1s/epoch - 3ms/step\n",
            "Epoch 130/200\n",
            "391/391 - 1s - loss: 0.3524 - accuracy: 0.8762 - val_loss: 3.0415 - val_accuracy: 0.5018 - 1s/epoch - 3ms/step\n",
            "Epoch 131/200\n",
            "391/391 - 1s - loss: 0.3450 - accuracy: 0.8770 - val_loss: 3.1126 - val_accuracy: 0.4872 - 1s/epoch - 3ms/step\n",
            "Epoch 132/200\n",
            "391/391 - 1s - loss: 0.3483 - accuracy: 0.8767 - val_loss: 3.0724 - val_accuracy: 0.5000 - 1s/epoch - 3ms/step\n",
            "Epoch 133/200\n",
            "391/391 - 1s - loss: 0.3617 - accuracy: 0.8735 - val_loss: 3.0292 - val_accuracy: 0.5062 - 1s/epoch - 3ms/step\n",
            "Epoch 134/200\n",
            "391/391 - 1s - loss: 0.3277 - accuracy: 0.8830 - val_loss: 3.1102 - val_accuracy: 0.5035 - 1s/epoch - 3ms/step\n",
            "Epoch 135/200\n",
            "391/391 - 1s - loss: 0.3219 - accuracy: 0.8866 - val_loss: 3.1908 - val_accuracy: 0.4972 - 1s/epoch - 3ms/step\n",
            "Epoch 136/200\n",
            "391/391 - 1s - loss: 0.3366 - accuracy: 0.8819 - val_loss: 3.0933 - val_accuracy: 0.5067 - 1s/epoch - 3ms/step\n",
            "Epoch 137/200\n",
            "391/391 - 1s - loss: 0.3254 - accuracy: 0.8836 - val_loss: 3.1882 - val_accuracy: 0.5007 - 1s/epoch - 3ms/step\n",
            "Epoch 138/200\n",
            "391/391 - 2s - loss: 0.3250 - accuracy: 0.8856 - val_loss: 3.2715 - val_accuracy: 0.4942 - 2s/epoch - 4ms/step\n",
            "Epoch 139/200\n",
            "391/391 - 2s - loss: 0.3233 - accuracy: 0.8861 - val_loss: 3.1709 - val_accuracy: 0.4996 - 2s/epoch - 4ms/step\n",
            "Epoch 140/200\n",
            "391/391 - 1s - loss: 0.3246 - accuracy: 0.8846 - val_loss: 3.2165 - val_accuracy: 0.4989 - 1s/epoch - 3ms/step\n",
            "Epoch 141/200\n",
            "391/391 - 1s - loss: 0.3332 - accuracy: 0.8825 - val_loss: 3.3320 - val_accuracy: 0.4959 - 1s/epoch - 3ms/step\n",
            "Epoch 142/200\n",
            "391/391 - 1s - loss: 0.3185 - accuracy: 0.8880 - val_loss: 3.4217 - val_accuracy: 0.4881 - 1s/epoch - 3ms/step\n",
            "Epoch 143/200\n",
            "391/391 - 1s - loss: 0.3029 - accuracy: 0.8938 - val_loss: 3.3812 - val_accuracy: 0.4922 - 1s/epoch - 3ms/step\n",
            "Epoch 144/200\n",
            "391/391 - 1s - loss: 0.3116 - accuracy: 0.8914 - val_loss: 3.3390 - val_accuracy: 0.4951 - 1s/epoch - 3ms/step\n",
            "Epoch 145/200\n",
            "391/391 - 1s - loss: 0.2984 - accuracy: 0.8952 - val_loss: 3.3482 - val_accuracy: 0.4995 - 1s/epoch - 3ms/step\n",
            "Epoch 146/200\n",
            "391/391 - 1s - loss: 0.2971 - accuracy: 0.8954 - val_loss: 3.5174 - val_accuracy: 0.4920 - 1s/epoch - 3ms/step\n",
            "Epoch 147/200\n",
            "391/391 - 1s - loss: 0.3014 - accuracy: 0.8942 - val_loss: 3.4548 - val_accuracy: 0.4940 - 1s/epoch - 3ms/step\n",
            "Epoch 148/200\n",
            "391/391 - 1s - loss: 0.2786 - accuracy: 0.9021 - val_loss: 3.4006 - val_accuracy: 0.5050 - 1s/epoch - 3ms/step\n",
            "Epoch 149/200\n",
            "391/391 - 1s - loss: 0.3066 - accuracy: 0.8920 - val_loss: 3.5085 - val_accuracy: 0.4921 - 1s/epoch - 3ms/step\n",
            "Epoch 150/200\n",
            "391/391 - 1s - loss: 0.2882 - accuracy: 0.8977 - val_loss: 3.4789 - val_accuracy: 0.4987 - 1s/epoch - 3ms/step\n",
            "Epoch 151/200\n",
            "391/391 - 1s - loss: 0.2650 - accuracy: 0.9065 - val_loss: 3.4340 - val_accuracy: 0.5076 - 1s/epoch - 3ms/step\n",
            "Epoch 152/200\n",
            "391/391 - 1s - loss: 0.2917 - accuracy: 0.8962 - val_loss: 3.5141 - val_accuracy: 0.4959 - 1s/epoch - 3ms/step\n",
            "Epoch 153/200\n",
            "391/391 - 1s - loss: 0.2854 - accuracy: 0.8993 - val_loss: 3.4544 - val_accuracy: 0.5015 - 1s/epoch - 3ms/step\n",
            "Epoch 154/200\n",
            "391/391 - 1s - loss: 0.2832 - accuracy: 0.9019 - val_loss: 3.5626 - val_accuracy: 0.5007 - 1s/epoch - 3ms/step\n",
            "Epoch 155/200\n",
            "391/391 - 1s - loss: 0.2746 - accuracy: 0.9035 - val_loss: 3.4856 - val_accuracy: 0.4942 - 1s/epoch - 3ms/step\n",
            "Epoch 156/200\n",
            "391/391 - 1s - loss: 0.2766 - accuracy: 0.9042 - val_loss: 3.5546 - val_accuracy: 0.4997 - 1s/epoch - 3ms/step\n",
            "Epoch 157/200\n",
            "391/391 - 1s - loss: 0.2770 - accuracy: 0.9020 - val_loss: 3.6058 - val_accuracy: 0.4985 - 1s/epoch - 3ms/step\n",
            "Epoch 158/200\n",
            "391/391 - 1s - loss: 0.2574 - accuracy: 0.9090 - val_loss: 3.6870 - val_accuracy: 0.4955 - 1s/epoch - 3ms/step\n",
            "Epoch 159/200\n",
            "391/391 - 1s - loss: 0.2675 - accuracy: 0.9051 - val_loss: 3.6771 - val_accuracy: 0.4909 - 1s/epoch - 3ms/step\n",
            "Epoch 160/200\n",
            "391/391 - 1s - loss: 0.2750 - accuracy: 0.9038 - val_loss: 3.6952 - val_accuracy: 0.4897 - 1s/epoch - 3ms/step\n",
            "Epoch 161/200\n",
            "391/391 - 1s - loss: 0.2561 - accuracy: 0.9073 - val_loss: 3.7190 - val_accuracy: 0.5017 - 1s/epoch - 3ms/step\n",
            "Epoch 162/200\n",
            "391/391 - 1s - loss: 0.2950 - accuracy: 0.8951 - val_loss: 3.7600 - val_accuracy: 0.4902 - 1s/epoch - 3ms/step\n",
            "Epoch 163/200\n",
            "391/391 - 1s - loss: 0.2500 - accuracy: 0.9121 - val_loss: 3.6113 - val_accuracy: 0.4914 - 1s/epoch - 3ms/step\n",
            "Epoch 164/200\n",
            "391/391 - 1s - loss: 0.2526 - accuracy: 0.9098 - val_loss: 3.6906 - val_accuracy: 0.4950 - 1s/epoch - 3ms/step\n",
            "Epoch 165/200\n",
            "391/391 - 2s - loss: 0.2339 - accuracy: 0.9167 - val_loss: 3.6997 - val_accuracy: 0.5042 - 2s/epoch - 4ms/step\n",
            "Epoch 166/200\n",
            "391/391 - 2s - loss: 0.2479 - accuracy: 0.9130 - val_loss: 3.6937 - val_accuracy: 0.4937 - 2s/epoch - 4ms/step\n",
            "Epoch 167/200\n",
            "391/391 - 1s - loss: 0.2803 - accuracy: 0.9014 - val_loss: 3.8071 - val_accuracy: 0.4994 - 1s/epoch - 3ms/step\n",
            "Epoch 168/200\n",
            "391/391 - 1s - loss: 0.2498 - accuracy: 0.9125 - val_loss: 3.7221 - val_accuracy: 0.4998 - 1s/epoch - 3ms/step\n",
            "Epoch 169/200\n",
            "391/391 - 1s - loss: 0.2298 - accuracy: 0.9189 - val_loss: 4.0073 - val_accuracy: 0.4846 - 1s/epoch - 3ms/step\n",
            "Epoch 170/200\n",
            "391/391 - 1s - loss: 0.2665 - accuracy: 0.9064 - val_loss: 3.8467 - val_accuracy: 0.4968 - 1s/epoch - 3ms/step\n",
            "Epoch 171/200\n",
            "391/391 - 1s - loss: 0.2254 - accuracy: 0.9207 - val_loss: 3.9582 - val_accuracy: 0.4902 - 1s/epoch - 3ms/step\n",
            "Epoch 172/200\n",
            "391/391 - 1s - loss: 0.2597 - accuracy: 0.9083 - val_loss: 3.7297 - val_accuracy: 0.5034 - 1s/epoch - 3ms/step\n",
            "Epoch 173/200\n",
            "391/391 - 1s - loss: 0.2414 - accuracy: 0.9161 - val_loss: 3.8108 - val_accuracy: 0.4996 - 1s/epoch - 3ms/step\n",
            "Epoch 174/200\n",
            "391/391 - 1s - loss: 0.2105 - accuracy: 0.9259 - val_loss: 3.9032 - val_accuracy: 0.4951 - 1s/epoch - 3ms/step\n",
            "Epoch 175/200\n",
            "391/391 - 1s - loss: 0.2162 - accuracy: 0.9238 - val_loss: 3.9376 - val_accuracy: 0.5002 - 1s/epoch - 3ms/step\n",
            "Epoch 176/200\n",
            "391/391 - 1s - loss: 0.2362 - accuracy: 0.9177 - val_loss: 4.0446 - val_accuracy: 0.4868 - 1s/epoch - 3ms/step\n",
            "Epoch 177/200\n",
            "391/391 - 1s - loss: 0.2543 - accuracy: 0.9112 - val_loss: 3.9677 - val_accuracy: 0.4964 - 1s/epoch - 3ms/step\n",
            "Epoch 178/200\n",
            "391/391 - 1s - loss: 0.2286 - accuracy: 0.9191 - val_loss: 3.9314 - val_accuracy: 0.4953 - 1s/epoch - 3ms/step\n",
            "Epoch 179/200\n",
            "391/391 - 1s - loss: 0.2285 - accuracy: 0.9193 - val_loss: 3.9403 - val_accuracy: 0.4981 - 1s/epoch - 3ms/step\n",
            "Epoch 180/200\n",
            "391/391 - 1s - loss: 0.1972 - accuracy: 0.9308 - val_loss: 4.0769 - val_accuracy: 0.4939 - 1s/epoch - 3ms/step\n",
            "Epoch 181/200\n",
            "391/391 - 1s - loss: 0.2212 - accuracy: 0.9223 - val_loss: 4.2253 - val_accuracy: 0.4707 - 1s/epoch - 3ms/step\n",
            "Epoch 182/200\n",
            "391/391 - 1s - loss: 0.2595 - accuracy: 0.9078 - val_loss: 3.9625 - val_accuracy: 0.5000 - 1s/epoch - 3ms/step\n",
            "Epoch 183/200\n",
            "391/391 - 1s - loss: 0.1970 - accuracy: 0.9303 - val_loss: 4.0951 - val_accuracy: 0.5044 - 1s/epoch - 3ms/step\n",
            "Epoch 184/200\n",
            "391/391 - 1s - loss: 0.2086 - accuracy: 0.9271 - val_loss: 4.1532 - val_accuracy: 0.4943 - 1s/epoch - 3ms/step\n",
            "Epoch 185/200\n",
            "391/391 - 1s - loss: 0.2374 - accuracy: 0.9164 - val_loss: 3.9694 - val_accuracy: 0.5052 - 1s/epoch - 3ms/step\n",
            "Epoch 186/200\n",
            "391/391 - 1s - loss: 0.2281 - accuracy: 0.9198 - val_loss: 4.0115 - val_accuracy: 0.4888 - 1s/epoch - 3ms/step\n",
            "Epoch 187/200\n",
            "391/391 - 1s - loss: 0.2150 - accuracy: 0.9244 - val_loss: 4.1088 - val_accuracy: 0.4959 - 1s/epoch - 3ms/step\n",
            "Epoch 188/200\n",
            "391/391 - 1s - loss: 0.2167 - accuracy: 0.9236 - val_loss: 4.1142 - val_accuracy: 0.4999 - 1s/epoch - 3ms/step\n",
            "Epoch 189/200\n",
            "391/391 - 1s - loss: 0.1899 - accuracy: 0.9328 - val_loss: 4.1183 - val_accuracy: 0.5007 - 1s/epoch - 3ms/step\n",
            "Epoch 190/200\n",
            "391/391 - 1s - loss: 0.2160 - accuracy: 0.9243 - val_loss: 4.1675 - val_accuracy: 0.4973 - 1s/epoch - 3ms/step\n",
            "Epoch 191/200\n",
            "391/391 - 1s - loss: 0.2201 - accuracy: 0.9229 - val_loss: 4.1706 - val_accuracy: 0.4848 - 1s/epoch - 3ms/step\n",
            "Epoch 192/200\n",
            "391/391 - 1s - loss: 0.1874 - accuracy: 0.9342 - val_loss: 4.1128 - val_accuracy: 0.4993 - 1s/epoch - 3ms/step\n",
            "Epoch 193/200\n",
            "391/391 - 1s - loss: 0.1926 - accuracy: 0.9321 - val_loss: 4.3840 - val_accuracy: 0.4820 - 1s/epoch - 3ms/step\n",
            "Epoch 194/200\n",
            "391/391 - 1s - loss: 0.2013 - accuracy: 0.9286 - val_loss: 4.3437 - val_accuracy: 0.4844 - 1s/epoch - 3ms/step\n",
            "Epoch 195/200\n",
            "391/391 - 1s - loss: 0.2444 - accuracy: 0.9140 - val_loss: 4.2573 - val_accuracy: 0.4850 - 1s/epoch - 3ms/step\n",
            "Epoch 196/200\n",
            "391/391 - 1s - loss: 0.1793 - accuracy: 0.9360 - val_loss: 4.2473 - val_accuracy: 0.5006 - 1s/epoch - 3ms/step\n",
            "Epoch 197/200\n",
            "391/391 - 1s - loss: 0.1926 - accuracy: 0.9335 - val_loss: 4.1710 - val_accuracy: 0.4954 - 1s/epoch - 3ms/step\n",
            "Epoch 198/200\n",
            "391/391 - 1s - loss: 0.2282 - accuracy: 0.9199 - val_loss: 4.2190 - val_accuracy: 0.4952 - 1s/epoch - 3ms/step\n",
            "Epoch 199/200\n",
            "391/391 - 1s - loss: 0.1807 - accuracy: 0.9360 - val_loss: 4.4885 - val_accuracy: 0.4860 - 1s/epoch - 3ms/step\n",
            "Epoch 200/200\n",
            "391/391 - 1s - loss: 0.1728 - accuracy: 0.9401 - val_loss: 4.3276 - val_accuracy: 0.4943 - 1s/epoch - 3ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa8e672c510>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 어떤 Hyper-parameter setting에서 최고의 성능이 나왔나요?\n",
        "# evaluate\n",
        "\n",
        "loss, acc = model.evaluate(X_test, y_test, batch_size=batch_size)\n",
        "print(\"Loss : %4.f, Test Accuracy : %.4f\" % (loss, acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0n4eErPuCls",
        "outputId": "d6f79bb7-1c0c-4a90-d025-ab0acf5e8f34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79/79 [==============================] - 0s 3ms/step - loss: 4.3276 - accuracy: 0.4943\n",
            "Loss :    4, Test Accuracy : 0.4943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "오버핏팅이 되면 optimizer, batch_size를 바꾸고\n",
        "언더핏팅이 되면 모델을 바꾸는게 효율적이다\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "yBo3mMnI9-tY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}